---
title: "Untitled"
author: "Daniel Hsiao"
date: "November 12, 2018"
output:
  pdf_document:
    fig_caption: yes
    fig_crop: no
    keep_tex: yes
    number_sections: yes
    toc: yes
    toc_depth: 3
header-includes:
    - \usepackage{placeins}
---

\newpage

# Methodology
## Standard Approach
Consider the two variable case here for illustration purpose. We have two forecasts, $y_1$ and $y_2$, of the true variable $y$. We want to combine $y_1$ and $y_2$ with a weight $w$ that we have $y_c = w y_1 + (1-w) y_2$. Assume they follow some distribution, e.g. $y_1 \sim D(0,\sigma_1)$, $y_2 \sim D(0,\sigma_2)$, and $corr(y_1,y_2)=\rho$. Then the variance of the combined forecast $y_c$ is
\begin{equation}
\label{eqn: var yc}
Var(y_c) = w^2\sigma_1^2+ (1-w)^2\sigma_2^2+2w(1-w)\sigma_1\sigma_2\rho,
\end{equation}
and the optimal weight with minimal variance is 
\begin{equation}
\label{eqn: simple weight}
w^*=\frac{\sigma_2^2-\sigma_1\sigma_2\rho}{\sigma_1^2+\sigma_2^2 -2\sigma_1\sigma_2\rho}.
\end{equation}

Equation \ref{eqn: simple weight} is the standard benchmark approach in the combination theory, where extensive research had been done on. **add research**. Equation \ref{eqn: simple weight} has a few empirical results that are against this approach. Two common alternatives are diagonal covariance matrix and equal weights.

Ignoring the correlation term $\rho$ by setting $\rho=0$, we get the inverse relation on the variance
\begin{equation}
\label{eqn: simple weight no corr}
w^*=\frac{\sigma_2^2}{\sigma_1^2+\sigma_2^2}.
\end{equation}
This is a robust way to avoid the estimation of the covariance when the dimension goes up. The amount of parameter to estimate for the covariance with dimension $n$ is $\frac{1}{2}n(n+1)$, which is quadratic in $n$. When the user only estimates the variances, the amount of parameter to estimate reduces to $n$, which greatly decreases the estimation error. **add citation**

Equal weights is another common approach that works better empirically. **add citation** The forecast combination is in this case just an arithmetric mean of all forecasts. The reason behind this is the fact that estimating weights increases or shifts the forecast errors due to additional estimation error in the estimation of $w$. We laborate on the estimation error of $w$ more later. 

**add more on equal weight**

## With estimation error of $w$

We can also consider the weight as non-deterministic, but related with $y$, e.g., in a trivairate distribution with finite third and fourth moments. Under trivariate distribution, the variance of the weights influences the expected value and the variance of the combined forecast. The expected value and the variance of the combined forecast becomes
\begin{equation}
\label{eqn: E & var yc w/ var w}
\begin{aligned}
  E(y_c) =& \mu + (cov(w, y_1-y_2))^2\\
var(y_c) =& E(w)^2\sigma_1^2 + (1-E(w))^2\sigma_2^2 + 2E(w)(1-E(w))\rho\sigma_1\sigma_2 \\
+& E[(w-E(w))(y_1-y_2) (E(w)y_1 + (1-E(w))y_2 - \mu)] \\
+& E[(w-E(w))^2 (y_1-y_2)^2] - cov(w,y_1-y_2)^2.
\end{aligned}
\end{equation}

Equation \ref{ eqn: E & var yc w/ var w} shows the general case of the forecast combination. If the covariance between $w$ and $y_1-y_2$ is not $0$, the forecast is biased when combining, with bias $cov(w, y_1-y_2)^2$. The variance also increases from euqation \ref{eqn: var yc} with $E[(w-E(w))(y_1-y_2) (E(w)y_1 + (1-E(w))y_2 - \mu)]+E[(w-E(w))^2 (y_1-y_2)^2] - cov(w,y_1-y_2)^2$. **can we prove that the change in var(yc) is positive? I tried to prove it but got stuck at $E[(w-E(w))(y_1-y_2) (E(w)y_1 + (1-E(w))y_2 - \mu)]+Var((w-Ew)(y_1-y_2))>0$**. This case the only requirements are that the individual forecast to be unbaised and that the weights sum up to 1.

Let $d = (d_1, d_2)'$ be the third moment between $y_1$, $y_2$, and $\begin{bmatrix} \sigma_{11} & \sigma_{12}\\ \sigma_{12} & \sigma_{22}\end{bmatrix}$ be the (co)variance matrix, we have
\begin{equation}
\label{eqn: w w/ var w}
\begin{aligned}
w^\dagger = w^*(1+\frac{\sigma_{22} d_1 + \sigma_{11} d_2 -\sigma_{12} (d_1 + d_2)}{\sigma_{11}\sigma_{22} - 2\sigma_{12}}) - \frac{\sigma_{22} d_1 - \sigma{12}d_2}{\sigma_{11}\sigma_{22} - 2\sigma_{12}}.
\end{aligned}
\end{equation}
The non-deterministic weight selection is a linear combination of the original weight. The non-deterministic weight does not change if the third moment is $0$.

## Negative weights
Looking back to equation \ref{eqn: simple weight}, we examin the effect of high correlation term. Assume without loss of generality that $\sigma_1 =\sigma_2 (1 + \delta)$, where $\delta>0$, we rewrite the weight as
\begin{equation}
\label{eqn: w high corr}
w = \frac{\sigma_2^2(-\rho\delta+ (1-\rho))}{\sigma_1^2+\sigma_2^2 -2\sigma_1\sigma_2\rho}.
\end{equation}
The numerator in $w$ consist of $\sigma_2^2$ scaled with a weighted mean between $-\delta$ and $1$ with weight $\rho$. When $\rho$ is small, the weights is close to equation \ref{eqn: simple weight no corr}. When $\rho$ is large, the negative difference in variance $-\delta$ takes over and results in negative weights. The level of negativity accounts for both the negtaive difference and correlation. The boundary case is 
\begin{equation}
\label{eqn: corr boundary}
\rho = \frac{\sigma_2}{\sigma_1},
\end{equation}
which $w$ decreases to $0$ and $y_c = y_2$.

From equation \ref{eqn: w w/ var w}, we look in the scaling parameter and the intercept adjustment vector. Under same condition where $\sigma_1 =\sigma_2 (1 + \delta)$, we rewrite the determinant to
\begin{equation}
\sigma_{11}\sigma_{22} - 2\sigma_{12} = \sigma_22 ((1+\delta)^2 - 2 (1+\delta)),
\end{equation}
and the scaling factors
\begin{equation}
\label{eqn: scaling factors}
\begin{aligned}
\frac{\sigma_{22} d_1 - \sigma{12}d_2}{\sigma_{11}\sigma_{22} - 2\sigma_{12}} =& \frac{d_1-\rho(1+\delta) d_2}{(1+\delta)^2 - 2 (1+\delta)}\\
\frac{\sigma_{22} d_1 + \sigma_{11} d_2 -\sigma_{12} (d_1 + d_2)}{\sigma_{11}\sigma_{22} - 2\sigma_{12}} =& \frac{d_1(1- \rho(1+\delta)) + d_2 ((1+\delta)^2-\rho(1+\delta)} {(1+\delta)^2 - 2 (1+\delta))}
\end{aligned}
\end{equation}

**and I'm lost in what I want to say**

## Truncated weights
To avoid the high correlated forecasts, we use truncation on the variable. The weight estimation is as follows
\begin{equation}
\label{eqn: w trunc}
** insert latex equation of truncation**
\end{equation}
where the sum of the weights are rescaled to 1.

Assume that there is no skewness in the joint distribution, e.g., $w^*$ is unbiased estimator of the true $w$. The expected value of the weights $\tilde{w}$ is 
\begin{equation}
\label{eqn: E w trunc}
\begin{aligned}
E(\tilde{w}) &= E(I_{w>c, w<1-c}w + I_{w>1-c})\\
&=\int_c^{1-c} wf(w)\,\mathrm{d}w+\int_c^{1-c} f(w)\,\mathrm{d}w.
\end{aligned}
\end{equation}
The bias is therefore
\begin{equation}
\label{eqn: bias w trunc}
\begin{aligned}
E(\tilde{w}) - E(w^*) &= \int_{-\infty}^{c} -wf(w)\,\mathrm{d}w+\int_{1-c}^{\infty} (1-w)f(w)\,\mathrm{d}w,
\end{aligned}
\end{equation}
In the first term, we have $w<c<0$, which cancels out the negative sign and becomes positive. In the second term we have $w>1-c>1$, which gives a negative value in $1-w$. In general case where $w$ can go above $1-c$ or below $c$ and the skewness of $w$ is not 0, the bias is non-zero. This increases MSE to the estimated $y_c$.

The variance is
\begin{equation}
\label{eqn: var w trunc}
\begin{aligned}
Var(\tilde{w}) &= E(\tilde{w}^{2})-E(\tilde{w})^2\\
&=\int_c^{1-c} w^2f(w)\,\mathrm{d}w+\int_c^{1-c} f(w)\,\mathrm{d}w - (\int_c^{1-c} wf(w)\,\mathrm{d}w+\int_{1-c}^{\infty} f(w)\,\mathrm{d}w)^2,
\end{aligned}
\end{equation}
And the change in variance is
\begin{equation}
\label{eqn: delta var w trunc 1}
\begin{aligned}
Var(\tilde{w}) - Var(w) &=\int_{-\infty}^{c} -w^2f(w)\,\mathrm{d}w+\int_{1-c}^{\infty} (1-w^2)f(w)\,\mathrm{d}w \\
& - (\int_c^{1-c} wf(w)\,\mathrm{d}w + \int_{1-c}^{\infty} f(w)\,\mathrm{d}w)^2 + (\int_{-\infty}^{\infty} wf(w)\,\mathrm{d}w)^2.
\end{aligned}
\end{equation}
By Cauchyâ€“Schwarz inequality, and take $g(w)$ as the weight generating function of $\tilde{w}$, we have
\begin{equation}
\label{eqn: delta var w trunc 2}
\begin{aligned}
Var(\tilde{w}) - Var(w) &\leq \int_{-\infty}^{c} -w^2f(w)\,\mathrm{d}w+\int_{1-c}^{\infty} (1-w^2)f(w)\,\mathrm{d}w \\
& - (\int_c^{\infty} g(w)f(w)\,\mathrm{d}w)^2 + \int_{-\infty}^{\infty} w^2f^2(w)\,\mathrm{d}w.
\end{aligned}
\end{equation}
Since $|g(w)|\leq|w|$ for all $w$, thus $g^2(w) \leq w^2$ for all $w$. Equation \ref{eqn: delta var w trunc 2} becomes **rewrite starting here**
\begin{equation}
\label{eqn: delta var w trunc 3}
\begin{aligned}
Var(\tilde{w}) - Var(w) &\geq \int_{-\infty}^{c} -w^2f(w)\,\mathrm{d}w+\int_{1-c}^{\infty} (1-w^2)f(w)\,\mathrm{d}w \\
& - \int_c^{\infty} w^2f^2(w)\,\mathrm{d}w + (\int_{-\infty}^{\infty} wf(w)\,\mathrm{d}w)^2.
\end{aligned}
\end{equation}
Since $f(w)\leq 1$ for all $w$, we have $f(w)\geq f^2(w)$ for all $w$. Rewrite into
\begin{equation}
\label{eqn: delta var w trunc 3}
\begin{aligned}
Var(\tilde{w}) - Var(w) &\geq \int_{-\infty}^{\infty} -w^2f(w)\,\mathrm{d}w+\int_{1-c}^{\infty} (1-w^2)f(w)\,\mathrm{d}w \\
& + (\int_{-\infty}^{\infty} wf(w)\,\mathrm{d}w)^2.
\end{aligned}
\end{equation}

## Bias Correction



# Survey of Professional Forecasters (SPF)
To illustrate the empirical results, we use the data from ECB **(footnote link to data)** in this paper. The data, SPF, is a quarterly survey initiated by ECB, with the aim to obtain future estimates on inflation (HICP), RGDP and unemployment rate (UNEM) from the private sector. Every quarter, a gourp of professional forecasters from financial and non-financial instutition, such as economic research institutions, respond to the survey with the idea on the future economic. Starting 1999, SPF is the longest survey of macroeconomic expectation in the euro area. Until the date of this paper, there are 75 quarters of observation available, with 1999 Q4 as the first forecasted value, and 2018 Q2 as the last observed true macroeconomic indice.

The set up of the survey consist of multiple magnitudes of questions, ranging from different horizon to different distribution. The forecaststers are asked to provide their point forecast and the probability of a certain scenario to happen. The survey enables ECB to do quantitative assessment on the consensus of the market, like the distribution statistics and standard deviations. For this paper, we take the 2 most answered time periods, which is 1 year ahead and 2 year ahead as our data set for all HICP, RGDP, and UNEM.

To compare the forecasts with the actual macroeconomics, we obtain the true value from ECB data base **(footnote link to data)**. The data cannot be observed from the economic in 100% accuracy within the first time frame, and exihibits changes to the initial estimates after revision. We use the final estimate of the macroeconomics where possible. The use of final estimate is fine is due to the fact that the original forecast is not the real target to be forecasts.

Within the datasets, not all forecasters did a forecast every time period. To avoid singular outliers, we remove all forecasters with a total forecasted period of less than 24 quarter (6 years). The removal approach is inline with **(ref paper)**. 

Following **(ref paper)**, we calculate the covariance by looking at the intersection between each forecasters. 

**insert equation**

When there are no intersection between 2 forecasters, we set the covariance value to 0. Additionally, we calculate the correlation by using the covariance divided by the standard deviation. Standard deviation is obtained from the square root of the diagonal.

\begin{equation}
\label{eqn: cov2cor}
\rho_{i,j} = \frac{\sigma_{i,j}}{\sigma_{i}\sigma_{j}}
\end{equation}

The cleaned up gives us a preliminary view on the SPF data without the noises.

\begin{figure}[!h]
\centering
\includegraphics{./Output/Images/SPF.png}
\caption{Survey of Professional Forecasters data illustration}\label{fig: SPF data illustration}
\end{figure}

\begin{table}
\centering
\caption{Summary statistics of the correlation of the forecast error. The correlation are split up into different forecast topics and different forecast horizons. For all of the series, the correlation are on average above 60%. In HICP and UNEM the correlation increases across all statistics when the forecast horizon increases, while RGDP remains the same.}
\label{tab: correlation summary statistics}
\begin{tabular}{lllllll}
\hline
Macro topic & \multicolumn{2}{c}{HICP} & \multicolumn{2}{c}{RGDP} & \multicolumn{2}{c}{UNEM} \\
Horizon     & 1 year & 2 year & 1 year & 2 year & 1 year & 2 year \\ \hline
min         & 0.03        & 0.02        & 0.11        & 0.13        & -0.02        & 0.08       \\
1st Q       & 0.53        & 0.62        & 0.63        & 0.65        & 0.47         & 0.56       \\
median      & 0.66        & 0.72        & 0.81        & 0.8         & 0.62         & 0.7        \\
mean        & 0.64        & 0.7         & 0.75        & 0.75        & 0.59         & 0.67       \\
3rd Q       & 0.77        & 0.81        & 0.89        & 0.87        & 0.74         & 0.8        \\
max         & 0.96        & 0.97        & 0.98        & 0.98        & 0.94         & 0.95       \\ 
\hline
\end{tabular}
\end{table}

In figure \ref{fig: SPF data illustration} and table \ref{tab: correlation summary statistics} we show the plots of the forecasts along side with the true value in the macroeconomics and the statistics of the covariance of the forecast error. To avoid too many lines on the figure by plotting all forecasts, we plot only the minimum, mean, and maximum from the forecasts. We see that there exist a high consistency across all forecasts, with two years ahead stronger than one year. The consistency in the forecast is lower in UNEM than the other two. Furthermore, many true values lies outside of the forecast range, with RGDP the worse of all three. More values outside of the forecast range suggest that restricting positive weights may be a strong limitation in the forecast combination. We expect to have large effect using truncation in the forecast of RGDP, while HICP and UNEM does not have too strong effect. We also expect the two year ahead forecast will be better than the one year ahead.

The table \ref{tab: correlation summary statistics} tell us on how the forecast error are correlated. The correlation are split up into different forecast topics and different forecast horizons. Diagonal element of the correlation matrix is not within the correlation when generating the summary statistics. For all of the series, the correlations are on average above 60%. In HICP and UNEM the correlation increases across all statistics when the forecast horizon increases, while RGDP remains the same. The lowest correlation to be found is -0.02, but this number is not too different than the minimum correlation in the other two topics.

**add more explanation**

# Empirical Results
## Proceure
The procedure to get the weights can be different between different researcher. Therefore we provide a through order of the steps we take in the weight estimation. We do the weights estimation for the truncation using the following steps:

Given each time to forecast, we take all the know observation before that forecast time period. 

1. Find the nearest positive definite covariance matrix. This step is required for the covariance to be invertible. We employ the nearPD function from r package *Matrix*. The nearPD function first decompose the covariance into univariate variance and the correlation. The function then uses the algorithm by *higham* on the correlation matrix to compute the nearest positive definite matrix. THe final results the the covariance matrix that is combined from the univariate variance and the correlation matrix.

2. Subset the covariance. Since there are more forecsaters in the estimation step than the amount of forecasters in the testing period, we take the sub matrix containing only the avaiable forecast on the testing period. That is, if 80 forecasters had made some forecasts before, but out of them, only 60 has a forecast this time, we discard the 20 extra forecasters.

3. Estimate the simple weight $w^*$ from equation \ref{eqn: simple weight}.

4. Truncate the weights with equation \ref{eqn: w trunc}. The weight no has less values and does not sum to one. Due to the fact that our selection of the truncation parameter are negative, the summation is higher than one and we scale down the weights accordingly.

5. Combine the forecast using the weights.

## Ratio of Mean Squared Prediction Error
We eavluate the performance of different weights by mean squared prediction error (MSPE). The trunacted MSPE is then compared with the MSPE from equal weight. 

\begin{table}[!h]
\centering
\caption{Mean Squared Prediction Error of inflation with different truncated value. The MSPE of the truncated value is given in the ratio of tuncation to euqal weights. Larger than 1 means truncated is worse, where as smaller than 1 means truncated weight helps in reducing MSPE.}
\label{my-label}
\begin{tabular}{lcccc}
          & \multicolumn{4}{c}{HICP}                                                \\
          \cmidrule{2-5}
          & \multicolumn{2}{c}{1 Year Horizon} & \multicolumn{2}{c}{2 Year Horizon} \\
          \cmidrule{2-3} \cmidrule{4-5}
Threshold & Truncated Ratio    & Equal MSPE    & Truncated Ratio    & Equal MSPE    \\
\cmidrule{1-1} \cmidrule{2-2} \cmidrule{3-3} \cmidrule{4-4} \cmidrule{5-5}
-Inf      & 3.29               & 0.74          & 2.21               & 1.47          \\
-10       & 2.82               & 0.74          & 2.21               & 1.47          \\
-9        & 2.82               & 0.74          & 2.21               & 1.47          \\
-8        & 2.82               & 0.74          & 2.21               & 1.47          \\
-7        & 2.82               & 0.74          & 2.21               & 1.47          \\
-6        & 2.82               & 0.74          & 2.08               & 1.47          \\
-5        & 2.82               & 0.74          & 2.11               & 1.47          \\
-4        & 2.82               & 0.74          & 2.15               & 1.47          \\
-3        & 2.82               & 0.74          & 1.55               & 1.47          \\
-2        & 0.81               & 0.74          & 0.99               & 1.47          \\
-1        & 0.88               & 0.74          & 0.98               & 1.47          \\
0         & 0.98               & 0.74          & 0.98               & 1.47          \\
\end{tabular}
\end{table}



